{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据优化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据优化的基本代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 70 µs, total: 70 µs\n",
      "Wall time: 72.7 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Greenlet at 0x7f0729e6b5f0: get_res(5)>,\n",
       " <Greenlet at 0x7f0729e6b710: get_res(5)>,\n",
       " <Greenlet at 0x7f0729e6b830: get_res(5)>,\n",
       " <Greenlet at 0x7f0729e6b950: get_res(5)>,\n",
       " <Greenlet at 0x7f0729e6ba70: get_res(5)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "# gevent的优化方法\n",
    "import gevent\n",
    "import requests\n",
    "import time\n",
    "     \n",
    "def get_res(data):\n",
    "    res = 1 + data\n",
    "    return res\n",
    "\n",
    "     \n",
    "\n",
    "g_lista = []\n",
    "\n",
    "for i in range(5):\n",
    "    g = gevent.spawn(get_res, 5)\n",
    "    g_lista.append(g)\n",
    "    # time.sleep(0.0001)\n",
    "\n",
    "g_lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.1 ms, sys: 38 µs, total: 32.1 ms\n",
      "Wall time: 30.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# jit加速代码\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "@jit     \n",
    "def comput_var(data,iter):\n",
    "    n = int(iter)\n",
    "    for i in range(n):\n",
    "        var = data + i \n",
    "    return var    \n",
    "\n",
    "comput_var(0,475)     \n",
    "\n",
    "\n",
    "# 62倍\n",
    "\n",
    "\n",
    "# g_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/liyuan3970/Data/My_Git/web_met/static/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 10:22:36,557\tWARNING services.py:1919 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 66912256 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=1.55gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=31707)\u001b[0m UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=31705)\u001b[0m UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=31703)\u001b[0m UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=31706)\u001b[0m UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=31709)\u001b[0m UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=31702)\u001b[0m UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=31704)\u001b[0m UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=31708)\u001b[0m UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'LocalFileOpener' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f2c67c42ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstation_Mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/liyuan3970/Data/My_Git/web_met/static/data/Mws2022.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/pandas/io.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_locals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf_locals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pd_read_csv_signature\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/pandas/io.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_update_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0msqueeze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"squeeze\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mpd_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFactoryDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;31m# This happens when `read_csv` returns a TextFileReader object for iterating through\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextFileReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/core/execution/dispatching/factories/dispatcher.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_inherit_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/core/execution/dispatching/factories/factories.py\u001b[0m in \u001b[0;36m_read_csv\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/core/io/file_dispatcher.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mpostprocessing\u001b[0m \u001b[0mwork\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mquery_compiler\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mquery_compiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;31m# TODO (devin-petersohn): Make this section more general for non-pandas kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# implementations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/core/io/text/text_file_dispatcher.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(cls, filepath_or_buffer, **kwargs)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0mheader_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                 \u001b[0mpre_reading\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_reading\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m             )\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/core/io/text/text_file_dispatcher.py\u001b[0m in \u001b[0;36mpartitioned_file\u001b[0;34m(cls, f, num_partitions, nrows, skiprows, quotechar, is_quoting, encoding, newline, header_size, pre_reading)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mrows_skipper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_reading\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/core/io/text/text_file_dispatcher.py\u001b[0m in \u001b[0;36mskipper\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m    493\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                     \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                     \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m                 )[1]\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/modin/core/io/text/text_file_dispatcher.py\u001b[0m in \u001b[0;36m_read_rows\u001b[0;34m(cls, f, nrows, quotechar, is_quoting, outside_quotes, encoding, newline)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_quoting\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquotechar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0moutside_quotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutside_quotes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LocalFileOpener' object is not iterable"
     ]
    }
   ],
   "source": [
    " !pwd\n",
    " import ray\n",
    " ray.init()\n",
    " from modin import pandas as pd\n",
    " station_Mws = pd.read_csv('/home/liyuan3970/Data/My_Git/web_met/static/data/Mws2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本完整的类脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行commput\n",
      "CPU times: user 3.01 s, sys: 89.9 ms, total: 3.1 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gevent\n",
    "from math import isnan\n",
    "import numpy as np\n",
    "# import modin.pandas as pd \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class sql_data:\n",
    "    def __init__(self, sql):\n",
    "        self.sql = sql  # 传进来的参数\n",
    "        station_Mws = pd.read_csv(\"Mws2022.csv\")\n",
    "        station_Aws = pd.read_csv(\"Aws2022.csv\")\n",
    "        self.station_all = pd.concat([station_Aws, station_Mws])\n",
    "        # 数据\n",
    "        self.grouped_county = self.station_all.groupby('county')\n",
    "        self.grouped_IIiii = self.station_all.groupby('IIiii')\n",
    "        self.timecounts = len(self.grouped_IIiii.get_group(58660)['tTime'])\n",
    "        # \n",
    "        # self.data_station = pd.DataFrame() \n",
    "        self.data_station = []\n",
    "        self.station_list = {}\n",
    "        self.symbol_ffy = ['path://M10 10L50 10 50 20 20 20 20 40 50 40 50 50 20 50 20 100 10 100 10 10z']\n",
    "        self.plot_data = {\n",
    "            'IIiii':[],\n",
    "            'lat':[],\n",
    "            'lon':[],\n",
    "            'county':[],\n",
    "            'town':[],\n",
    "            'name':[],\n",
    "            'fFy':[],\n",
    "            'rsum':[],\n",
    "            'rmax':[]\n",
    "            }\n",
    "\n",
    "    def data_gevent(self,data):\n",
    "        # print(\"data_gevent\")\n",
    "        station_RR_small = 0.0\n",
    "        station_RR_mid = 0.0\n",
    "        station_RR_big = 0.0\n",
    "        station_RR_huge = 0.0\n",
    "        station_RR_bighuge = 0.0\n",
    "        station_RR_more = 0.0\n",
    "\n",
    "        station_wind7 = 0.0\n",
    "        station_wind8 = 0.0\n",
    "        station_wind9 = 0.0\n",
    "        station_wind10 = 0.0\n",
    "        station_wind11 = 0.0\n",
    "        station_wind12 = 0.0\n",
    "        station_wind13 = 0.0\n",
    "        station_wind14 = 0.0\n",
    "        station_wind15 = 0.0\n",
    "        station_wind16 = 0.0\n",
    "        station_wind17 = 0.0\n",
    "\n",
    "        station_VV_small = 0.0\n",
    "        station_VV_mid = 0.0\n",
    "        station_VV_big = 0.0\n",
    "        station_VV_huge = 0.0\n",
    "        station_VV_more = 0.0\n",
    "\n",
    "        value_rsum = data['RR'].sum()\n",
    "        fFy_data = data['fFy'].max()/10.0\n",
    "        value_VV = data['VV'].min()\n",
    "\n",
    "\n",
    "\n",
    "        if value_rsum >= 0 and value_rsum < 10:\n",
    "            station_RR_small = station_RR_small + 0\n",
    "        elif value_rsum >= 9 and value_rsum < 25:\n",
    "            station_RR_mid = station_RR_mid+0\n",
    "        elif value_rsum >= 24 and value_rsum < 50:\n",
    "            station_RR_big = station_RR_big + 0\n",
    "        elif value_rsum >= 49 and value_rsum < 100:\n",
    "            station_RR_huge = station_RR_huge+0\n",
    "        elif value_rsum >= 99 and value_rsum < 250:\n",
    "            station_RR_RR_bighuge = station_RR_bighuge+0\n",
    "        else:\n",
    "            station_RR_more = station_RR_more+0\n",
    "        # 大风\n",
    "\n",
    "\n",
    "        if fFy_data > 12.8 and fFy_data <= 17.1:\n",
    "            station_wind6 = station_wind7 + 1\n",
    "        elif fFy_data > 16.1 and fFy_data <= 20.7:\n",
    "            station_wind7 = station_wind8 + 1\n",
    "        elif fFy_data > 19.7 and fFy_data <= 24.4:\n",
    "            station_wind8 = station_wind9 + 1\n",
    "        elif fFy_data > 23.4 and fFy_data <= 28.4:\n",
    "            station_wind9 = station_wind10 + 1\n",
    "        elif fFy_data > 27.4 and fFy_data <= 32.6:\n",
    "            station_wind10 = station_wind11 + 1\n",
    "        elif fFy_data > 31.6 and fFy_data <= 36.9:\n",
    "            station_wind11 = station_wind12 + 1\n",
    "        elif fFy_data > 35.9 and fFy_data <= 41.4:\n",
    "            station_wind12 = station_wind13 + 1\n",
    "        elif fFy_data > 40.4 and fFy_data <= 46.1:\n",
    "            station_wind13 = station_wind14 + 1\n",
    "        elif fFy_data > 45.1 and fFy_data <= 51.0:\n",
    "            station_wind14 = station_wind15 + 1\n",
    "        elif fFy_data > 50.0 and fFy_data <= 56.1:\n",
    "            station_wind15 = station_wind16 + 1\n",
    "        else:\n",
    "            station_wind16 = station_wind17 + 1\n",
    "\n",
    "        # 能见度\n",
    "\n",
    "        if value_VV >= 0 and value_VV < 50:\n",
    "            station_VV_small = station_VV_small + 0\n",
    "        elif value_VV >= 49 and value_VV < 200:\n",
    "            station_VV_mid = station_VV_mid+0\n",
    "        elif value_VV >= 199 and value_VV < 500:\n",
    "            station_VV_big = station_VV_big + 0\n",
    "        elif value_VV >= 499 and value_VV < 1000:\n",
    "            station_VV_huge = station_VV_huge+0\n",
    "        else:\n",
    "            station_VV_more = station_VV_more+0\n",
    "        # 绘图、排序数据\n",
    "        self.plot_data['IIiii'].append(data['IIiii'].iloc[0])  \n",
    "        self.plot_data['lat'].append(data['lat'].iloc[0]) \n",
    "        self.plot_data['lon'].append(data['lon'].iloc[0])\n",
    "        self.plot_data['county'].append(data['county'].iloc[0])\n",
    "        self.plot_data['name'].append(data['StationName'].iloc[0])\n",
    "        self.plot_data['fFy'].append(fFy_data)\n",
    "        self.plot_data['rsum'].append(value_rsum/10.0)\n",
    "        self.plot_data['rmax'].append(data['RR'].max()/10.0)\n",
    "        # self.plot_data['tmax'].append(data['Tx'].max()/10.0)\n",
    "        # self.plot_data['tmin'].append(data['Tn'].min()/10.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.dic_station = {'IIiii': data['IIiii'].iloc[0],\n",
    "                   'StationName': data['StationName'].iloc[0],\n",
    "                   'County': data['county'].iloc[0],\n",
    "                   'Town': data['Town'].iloc[0],\n",
    "                   'lat': data['lat'].iloc[0],\n",
    "                   'lon': data['lon'].iloc[0],\n",
    "                   'rsum': value_rsum/10.0,\n",
    "                   'rmax': data['RR'].max()/10.0,\n",
    "                   'tmax': data['Tx'].max()/10.0,\n",
    "                   'tmin': data['Tn'].min()/10.0,\n",
    "                   'vmin': value_VV,\n",
    "                   'fmax': fFy_data,\n",
    "                   'dfx': data[data['fFy'] == data['fFy'].min()]['dFy'].iloc[0],\n",
    "                   'label_rsm': value_rsum/10.0,\n",
    "                   'label_tx': data['RR'].max()/10.0,\n",
    "                   'label_tn': data['Tn'].min()/10.0,\n",
    "                   'label_tworn': data['StationName'].iloc[0],\n",
    "                   'label_v': data['VV'].min(),\n",
    "                   'label_fy': data['StationName'].iloc[0],\n",
    "                   'url_r': \"station/\"+str(data['IIiii'].iloc[0])+\"/rain/\",\n",
    "                   'url_t': \"station/\"+str(data['IIiii'].iloc[0])+\"/temp/\",\n",
    "                   'url_v': \"station/\"+str(data['IIiii'].iloc[0])+\"/vv/\",\n",
    "                   'url_fy': \"station/\"+str(data['IIiii'].iloc[0])+\"/fFy/\",\n",
    "                   'name_r': data['StationName'].iloc[0],\n",
    "                   'name_t': data['StationName'].iloc[0],\n",
    "                   'name_v': data['StationName'].iloc[0],\n",
    "                   'name_fy': data['StationName'].iloc[0],\n",
    "                   'value':[\n",
    "                       data['lon'].iloc[0],\n",
    "                       data['lat'].iloc[0],\n",
    "                       value_rsum/10.0,\n",
    "                       data['RR'].max()/10.0,\n",
    "                       value_VV,\n",
    "                       fFy_data,\n",
    "                       data['Tx'].max()/10.0,\n",
    "                       data['Tn'].min()/10.0\n",
    "                   ],\n",
    "                   'symbol':str(self.symbol_ffy[0]) ,\n",
    "                   'symbolRotate':data[data['fFy'] == data['fFy'].min()]['dFy'].iloc[0],\n",
    "\n",
    "                   }\n",
    "        # self.data_station = self.data_station.append(self.dic_station, ignore_index=True)\n",
    "        self.data_station.append(self.dic_station)\n",
    "        self.station_list_dir = {\n",
    "        'time': data['tTime'].tolist(),\n",
    "        'T': data['T'].tolist(),\n",
    "        'V': data['VV'].tolist(),\n",
    "        'fFy': data['fFy'].tolist(),\n",
    "        'dFy': data['dFy'].tolist()\n",
    "        }\n",
    "        self.station_list[str(data['IIiii'].iloc[0])] = self.station_list_dir\n",
    "        # print(self.data_station)\n",
    "        \n",
    "        \n",
    "        # return station_list,data_station\n",
    "\n",
    "\n",
    "    def comput_IIiii(self):\n",
    "        '返回pandas、字典串、列表'\n",
    "\n",
    "        print(\"运行commput\")\n",
    "\n",
    "\n",
    "        ffy_rank = [0, 0, 0]\n",
    "        vv_rank = [0, 0, 0, 0, 0]\n",
    "        t_rank = [0, 0, 0]\n",
    "        for i in self.grouped_IIiii.size().index:\n",
    "            # print(\"i:\",i)\n",
    "            data = self.grouped_IIiii.get_group(i)\n",
    "            data['VV'].replace(-9999, np.nan, inplace=True)\n",
    "            data['RR'].replace(-9999, np.nan, inplace=True)\n",
    "            data['Tn'].replace(-9999, np.nan, inplace=True)\n",
    "            data['Tx'].replace(-9999, np.nan, inplace=True)\n",
    "            self.data_gevent(data)\n",
    "            # g = gevent.spawn(data_gevent, data)\n",
    "    # 数据排序\n",
    "    def return_data_sort(self,sort_data,value_str):\n",
    "        value_str = 'rsum'\n",
    "        sort_data['index'] = sort_data['fFy'].rank(ascending=0,method='dense')\n",
    "        sort_out = sort_data.sort_values(by =['fFy'],ascending = [False])  \n",
    "        list_data = []\n",
    "        for row in sort_out.itertuples():\n",
    "            dic_iter = {'index':int(getattr(row, 'index')),'IIiii':str(getattr(row, 'name')),\n",
    "            'county':getattr(row, 'county'),'town':getattr(row, 'town'),'data':getattr(row, value_str)}\n",
    "            list_data.append(dic_iter)\n",
    "        return list_data\n",
    "    # 数据绘图\n",
    "    def plot_data(self,plot_data,value_str):\n",
    "        value_str = 'rsum'\n",
    "        lat = plot_data['lat']\n",
    "        lon = plot_data['lon']\n",
    "        value = plot_data[value_str]\n",
    "        # plot_func()\n",
    "        return img \n",
    "\n",
    "\n",
    "\n",
    "sql = 'test'\n",
    "a = sql_data(sql)\n",
    "a.comput_IIiii()\n",
    "b= a.data_station\n",
    "# # c =a.data_fFy\n",
    "# d = a.timecounts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.47 s, sys: 109 ms, total: 5.58 s\n",
      "Wall time: 5.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from math import isnan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def data_gevent(data):\n",
    "    # 绘图数据处理\n",
    "\n",
    "    dic_station = {'IIiii': data['IIiii'].iloc[0],\n",
    "                   'StationName': data['StationName'].iloc[0],\n",
    "                   'County': data['county'].iloc[0],\n",
    "                   'Town': data['Town'].iloc[0],\n",
    "                   'lat': data['lat'].iloc[0],\n",
    "                   'lon': data['lon'].iloc[0],\n",
    "                   'rsum': value_rsum/10.0,\n",
    "                   'rmax': data['RR'].max()/10.0,\n",
    "                   'tmax': data['RR'].max()/10.0,\n",
    "                   'tmin': data['Tn'].min()/10.0,\n",
    "                   'vmin': data['VV'].min(),\n",
    "                   'fmax': fFy_data,\n",
    "                   'dfx': data[data['fFy'] == data['fFy'].min()]['dFy'].iloc[0],\n",
    "                   'label_rsm': value_rsum/10.0,\n",
    "                   'label_tx': data['RR'].max()/10.0,\n",
    "                   'label_tn': data['Tn'].min()/10.0,\n",
    "                   'label_tworn': data['StationName'].iloc[0],\n",
    "                   'label_v': data['VV'].min(),\n",
    "                   'label_fy': data['StationName'].iloc[0],\n",
    "                   'url_r': \"station/\"+str(data['IIiii'].iloc[0])+\"/rain/\",\n",
    "                   'url_t': \"station/\"+str(data['IIiii'].iloc[0])+\"/temp/\",\n",
    "                   'url_v': \"station/\"+str(data['IIiii'].iloc[0])+\"/vv/\",\n",
    "                   'url_fy': \"station/\"+str(data['IIiii'].iloc[0])+\"/fFy/\",\n",
    "                   'name_r': data['StationName'].iloc[0],\n",
    "                   'name_t': data['StationName'].iloc[0],\n",
    "                   'name_v': data['StationName'].iloc[0],\n",
    "                   'name_fy': data['StationName'].iloc[0]\n",
    "                   }\n",
    "    data_station = data_station.append(dic_station, ignore_index=True)\n",
    "#             data_station.append(dic_station)\n",
    "    # 单站数据导出\n",
    "    station_list_dir = {\n",
    "        'time': data['tTime'].tolist(),\n",
    "        'T': data['VV'].tolist(),\n",
    "        'V': data['VV'].tolist(),\n",
    "        'fFy': data['fFy'].tolist(),\n",
    "        'dFy': data['dFy'].tolist()\n",
    "    }\n",
    "    station_list[str(data['IIiii'].iloc[0])] = station_list_dir\n",
    "\n",
    "\n",
    "class sql_data:\n",
    "    def __init__(self, sql):\n",
    "        self.sql = sql  # 传进来的参数\n",
    "        station_Mws = pd.read_csv(\"Mws2022.csv\")\n",
    "        station_Aws = pd.read_csv(\"Aws2022.csv\")\n",
    "        self.station_all = pd.concat([station_Aws, station_Mws])\n",
    "        # 数据\n",
    "        self.grouped_county = self.station_all.groupby('county')\n",
    "        self.grouped_IIiii = self.station_all.groupby('IIiii')\n",
    "        self.timecounts = len(self.grouped_IIiii.get_group(58660)['tTime'])\n",
    "\n",
    "    def comput_IIiii(self):\n",
    "        '返回pandas、字典串、列表'\n",
    "        data_station = pd.DataFrame()\n",
    "#         data_station = pd.DataFrame()\n",
    "        station_list = {}  # []\n",
    "\n",
    "        station_RR_small = 0.0\n",
    "        station_RR_mid = 0.0\n",
    "        station_RR_big = 0.0\n",
    "        station_RR_huge = 0.0\n",
    "        station_RR_bighuge = 0.0\n",
    "        station_RR_more = 0.0\n",
    "\n",
    "        station_wind7 = 0.0\n",
    "        station_wind8 = 0.0\n",
    "        station_wind9 = 0.0\n",
    "        station_wind10 = 0.0\n",
    "        station_wind11 = 0.0\n",
    "        station_wind12 = 0.0\n",
    "        station_wind13 = 0.0\n",
    "        station_wind14 = 0.0\n",
    "        station_wind15 = 0.0\n",
    "        station_wind16 = 0.0\n",
    "        station_wind17 = 0.0\n",
    "\n",
    "        station_VV_small = 0.0\n",
    "        station_VV_mid = 0.0\n",
    "        station_VV_big = 0.0\n",
    "        station_VV_huge = 0.0\n",
    "        station_VV_more = 0.0\n",
    "\n",
    "        ffy_rank = [0, 0, 0]\n",
    "        vv_rank = [0, 0, 0, 0, 0]\n",
    "        t_rank = [0, 0, 0]\n",
    "        for i in self.grouped_IIiii.size().index:\n",
    "            data = self.grouped_IIiii.get_group(i)\n",
    "            data['VV'].replace(-9999, np.nan, inplace=True)\n",
    "            data['RR'].replace(-9999, np.nan, inplace=True)\n",
    "            data['Tn'].replace(-9999, np.nan, inplace=True)\n",
    "            data['Tx'].replace(-9999, np.nan, inplace=True)\n",
    "            # 量级分类\n",
    "            # 降水\n",
    "            if not isnan(data['RR'].sum()):\n",
    "                value_rsum = data['RR'].sum()\n",
    "                if value_rsum >= 0 and value_rsum < 10:\n",
    "                    station_RR_small = station_RR_small + 1\n",
    "                elif value_rsum >= 10 and value_rsum < 25:\n",
    "                    station_RR_mid = station_RR_mid+1\n",
    "                elif value_rsum >= 25 and value_rsum < 50:\n",
    "                    station_RR_big = station_RR_big + 1\n",
    "                elif value_rsum >= 50 and value_rsum < 100:\n",
    "                    station_RR_huge = station_RR_huge+1\n",
    "                elif value_rsum >= 100 and value_rsum < 250:\n",
    "                    station_RR_RR_bighuge = station_RR_bighuge+1\n",
    "                else:\n",
    "                    station_RR_more = station_RR_more+1\n",
    "            # 大风\n",
    "\n",
    "            if not isnan(data['fFy'].max()):\n",
    "                fFy_data = data['fFy'].max()/10.0\n",
    "                if fFy_data > 13.8 and fFy_data <= 17.1:\n",
    "                    station_wind7 = station_wind7 + 1\n",
    "                elif fFy_data > 17.1 and fFy_data <= 20.7:\n",
    "                    station_wind8 = station_wind8 + 1\n",
    "                elif fFy_data > 20.7 and fFy_data <= 24.4:\n",
    "                    station_wind9 = station_wind9 + 1\n",
    "                elif fFy_data > 24.4 and fFy_data <= 28.4:\n",
    "                    station_wind10 = station_wind10 + 1\n",
    "                elif fFy_data > 28.4 and fFy_data <= 32.6:\n",
    "                    station_wind11 = station_wind11 + 1\n",
    "                elif fFy_data > 32.6 and fFy_data <= 36.9:\n",
    "                    station_wind12 = station_wind12 + 1\n",
    "                elif fFy_data > 36.9 and fFy_data <= 41.4:\n",
    "                    station_wind13 = station_wind13 + 1\n",
    "                elif fFy_data > 41.4 and fFy_data <= 46.1:\n",
    "                    station_wind14 = station_wind14 + 1\n",
    "                elif fFy_data > 46.1 and fFy_data <= 51.0:\n",
    "                    station_wind15 = station_wind15 + 1\n",
    "                elif fFy_data > 51.0 and fFy_data <= 56.1:\n",
    "                    station_wind16 = station_wind16 + 1\n",
    "                else:\n",
    "                    station_wind17 = station_wind17 + 1\n",
    "\n",
    "            # 能见度\n",
    "            if not isnan(data['VV'].min()):\n",
    "                value_VV = data['VV'].min()\n",
    "#                 print(value_VV)\n",
    "                if value_VV >= 0 and value_VV < 50:\n",
    "                    station_VV_small = station_VV_small + 1\n",
    "                elif value_VV >= 50 and value_VV < 200:\n",
    "                    station_VV_mid = station_VV_mid+1\n",
    "                elif value_VV >= 200 and value_VV < 500:\n",
    "                    station_VV_big = station_VV_big + 1\n",
    "                elif value_VV >= 500 and value_VV < 1000:\n",
    "                    station_VV_huge = station_VV_huge+1\n",
    "                else:\n",
    "                    station_VV_more = station_VV_more+1\n",
    "\n",
    "            # 绘图数据处理\n",
    "            dic_station = {'IIiii': data['IIiii'].iloc[0],\n",
    "                           'StationName': data['StationName'].iloc[0],\n",
    "                           'County': data['county'].iloc[0],\n",
    "                           'Town': data['Town'].iloc[0],\n",
    "                           'lat': data['lat'].iloc[0],\n",
    "                           'lon': data['lon'].iloc[0],\n",
    "                           'rsum': value_rsum/10.0,\n",
    "                           'rmax': data['RR'].max()/10.0,\n",
    "                           'tmax': data['RR'].max()/10.0,\n",
    "                           'tmin': data['Tn'].min()/10.0,\n",
    "                           'vmin': data['VV'].min(),\n",
    "                           'fmax': fFy_data,\n",
    "                           'dfx': data[data['fFy'] == data['fFy'].min()]['dFy'].iloc[0],\n",
    "                           'label_rsm': value_rsum/10.0,\n",
    "                           'label_tx': data['RR'].max()/10.0,\n",
    "                           'label_tn': data['Tn'].min()/10.0,\n",
    "                           'label_tworn': data['StationName'].iloc[0],\n",
    "                           'label_v': data['VV'].min(),\n",
    "                           'label_fy': data['StationName'].iloc[0],\n",
    "                           'url_r': \"station/\"+str(data['IIiii'].iloc[0])+\"/rain/\",\n",
    "                           'url_t': \"station/\"+str(data['IIiii'].iloc[0])+\"/temp/\",\n",
    "                           'url_v': \"station/\"+str(data['IIiii'].iloc[0])+\"/vv/\",\n",
    "                           'url_fy': \"station/\"+str(data['IIiii'].iloc[0])+\"/fFy/\",\n",
    "                           'name_r': data['StationName'].iloc[0],\n",
    "                           'name_t': data['StationName'].iloc[0],\n",
    "                           'name_v': data['StationName'].iloc[0],\n",
    "                           'name_fy': data['StationName'].iloc[0]\n",
    "                           }\n",
    "            data_station = data_station.append(dic_station, ignore_index=True)\n",
    "#             data_station.append(dic_station)\n",
    "            # 单站数据导出\n",
    "            station_list_dir = {\n",
    "                'time': data['tTime'].tolist(),\n",
    "                'T': data['VV'].tolist(),\n",
    "                'V': data['VV'].tolist(),\n",
    "                'fFy': data['fFy'].tolist(),\n",
    "                'dFy': data['dFy'].tolist()\n",
    "            }\n",
    "            station_list[str(data['IIiii'].iloc[0])] = station_list_dir\n",
    "#         # 数据排序\n",
    "        data_station['ind_fFy'] = data_station['fmax'].rank(\n",
    "            ascending=0, method='dense')\n",
    "        data_station['ind_rx'] = data_station['rmax'].rank(\n",
    "            ascending=0, method='dense')\n",
    "        data_station['ind_rm'] = data_station['rsum'].rank(\n",
    "            ascending=0, method='dense')\n",
    "        data_fFy = data_station.sort_values(by=['ind_fFy'], ascending=[False])\n",
    "        data_rsum = data_station.sort_values(by =['rsum'],ascending = [False])\n",
    "        data_rmax = data_station.sort_values(by =['rmax'],ascending = [False])\n",
    "\n",
    "\n",
    "sql = 'test'\n",
    "a = sql_data(sql).comput_IIiii()\n",
    "\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c\n",
       "0  2.0  3.0  0.0\n",
       "1  2.0  3.0  1.0\n",
       "2  2.0  3.0  2.0\n",
       "3  2.0  3.0  3.0\n",
       "4  2.0  3.0  4.0\n",
       "5  2.0  3.0  5.0\n",
       "6  2.0  3.0  6.0\n",
       "7  2.0  3.0  7.0\n",
       "8  2.0  3.0  8.0\n",
       "9  2.0  3.0  9.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    dic = {'a': 2, 'b': 3, 'c': i}\n",
    "    data = data.append(dic, ignore_index=True)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             IIiii.append(data['IIiii'].iloc[0])\n",
    "#             StationName.append(data['StationName'].iloc[0])\n",
    "#             County.append(data['county'].iloc[0])\n",
    "#             Town.append(data['Town'].iloc[0])\n",
    "#             lat.append(data['lat'].iloc[0])\n",
    "#             rsum.append(data['RR'].sum()/10.0)\n",
    "#             rmax.append(data['RR'].max()/10.0)\n",
    "#             tmax.append(data['Tx'].max()/10.0)\n",
    "#             tmin.append(data['Tn'].min()/10.0)\n",
    "#             vmin.append(data['VV'].min()/10.0)\n",
    "#             fmax.append(data['fFy'].max()/10.0)\n",
    "#             dfx.append(data[data['fFy']== data['fFy'].max()]['dFy'].iloc[0])\n",
    "\n",
    "\n",
    "#         columns=['IIiii','StationName','County','Town',\n",
    "#                  'lat', 'lon','rsum','rmax','tmax','tmin',\n",
    "#                 'vmin','fmax','dfx',\n",
    "#                 'label_rsm','label_tx','label_tn','label_tworn','label_v','label_fy'\n",
    "#                 'url_r','url_t','url_v','url_fy',\n",
    "#                  'name_r','name_t','name_v','name_fy'\n",
    "#                 ]\n",
    "#         data_station = pd.DataFrame(columns=columns)\n",
    "#         dic_station = { }\n",
    "#         station_list = {}#[]\n",
    "\n",
    "#         IIiii = []\n",
    "#         StationName = []\n",
    "#         County = []\n",
    "#         Town = []\n",
    "#         lat = []\n",
    "#         lon = []\n",
    "#         rsum = []\n",
    "#         rmax = []\n",
    "#         tmax = []\n",
    "#         tmin = []\n",
    "#         vmin = []\n",
    "#         fmax = []\n",
    "#         dfx = []\n",
    "#         label_rsm = []\n",
    "#         label_tx = []\n",
    "#         label_tn = []\n",
    "#         label_tworn = []\n",
    "#         label_v = []\n",
    "#         label_fy = []\n",
    "#         url_r = []\n",
    "#         url_t = []\n",
    "#         url_v = []\n",
    "#         url_fy = []\n",
    "#         name_r = []\n",
    "#         name_t = []\n",
    "#         name_v = []\n",
    "#         name_fy = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
