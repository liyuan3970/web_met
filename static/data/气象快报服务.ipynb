{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EC数据的查询\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.92 ms, sys: 515 µs, total: 7.44 ms\n",
      "Wall time: 22.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pymssql \n",
    "import pandas as pd\n",
    "\n",
    "## 连接数据库\n",
    "server = '172.21.158.201'    # 连接服务器地址\n",
    "user = 'down'# 连接帐号\n",
    "password = 'downx'# 连接密码\n",
    "conn = pymssql.connect(server, user, password, 'ZJSZDZDB')  #获取连接\n",
    "\n",
    "sql_all = '''\n",
    "select IIiii,lat,lon FROM TAB_StationInfo\n",
    "WHERE (IIiii  IN  ('58566','58567','58564','58569','58556','58555','58560','58654','58657','58658','58763','58656','58761','58559','58568','58660','58662','58663','58653','58652','58655','58665','58661','58666','58664','58669','58667','58668','K8705','K8706','K8818','K8609','K8821','K8611','K8903','K8910','K8282','K8217','K8201','K8301','K8413','K8505'))\n",
    "'''\n",
    "df = pd.read_sql(sql_all , con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编写自动站数据的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 344 µs, total: 140 ms\n",
      "Wall time: 161 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "class sql_plot:\n",
    "    def __init__(self, start_time,end_time,select_type):\n",
    "        self.start =  start_time \n",
    "        self.end = end_time\n",
    "        self.type = select_type\n",
    "        self.station = ('58566','58567','58564','58569','58556','58555','58560','58654','58657','58658','58763','58656','58761','58559','58568','58660','58662','58663','58653','58652','58655','58665','58661','58666','58664','58669','58667','58668','K8705','K8706','K8818','K8609','K8821','K8611','K8903','K8910','K8282','K8217','K8201','K8301','K8413','K8505')\n",
    "        self.Aws = ('58566','58567','58564','58569','58556','58555','58560','58654','58657','58658','58763','58656','58761','58559','58568','58660','58662','58663','58653','58652','58655','58665','58661','58666','58664','58669','58667','58668')\n",
    "        self.Mws = ('K8705','K8706','K8818','K8609','K8821','K8611','K8903','K8910','K8282','K8217','K8201','K8301','K8413','K8505')  \n",
    "        self.server = '127.0.0.1' \n",
    "        self.user = 'root'\n",
    "        self.password = '051219'# 连接密码   \n",
    "        self.port = 3306\n",
    "        self.database = \"ZJSZDZDB\"\n",
    "    def return_zdz_data(self):\n",
    "        self.start =\"'\" +  self.start + \"'\" \n",
    "        self.end = \"'\" +  self.end + \"'\" \n",
    "        conn = pymysql.connect(\n",
    "            host = self.server, \n",
    "            port = self.port,\n",
    "            user = self.user, \n",
    "            password = self.password,\n",
    "            database = self.database)\n",
    "        sql_Aws = f'''select a.IIiii,b.lat,b.lon,SUM(a.RR)/10.0\n",
    "            from TAB_Aws2019 AS a left join TAB_StationInfo AS b on a.IIiii=b.IIiii \n",
    "            WHERE (b.IIiii  IN  {self.Aws} and (tTime BETWEEN {self.start} and {self.end} )) \n",
    "            GROUP BY a.IIiii,lat,lon'''\n",
    "        sql_Mws = f'''select a.IIiii,b.lat,b.lon,SUM(a.RR)/10.0\n",
    "            from TAB_Mws2019 AS a left join TAB_StationInfo AS b on a.IIiii=b.IIiii \n",
    "            WHERE (b.IIiii  IN  {self.Mws} and (tTime BETWEEN {self.start} and {self.end} )) \n",
    "            GROUP BY a.IIiii,lat,lon '''\n",
    "        dfa = pd.read_sql(sql_Aws, con=conn)\n",
    "        dfm = pd.read_sql(sql_Mws, con=conn)\n",
    "        df = pd.concat([dfa,dfm])\n",
    "        # 输出数据\n",
    "        data_canvas = {\n",
    "            \"station_list\": [],\n",
    "            \"station\": []\n",
    "        }\n",
    "        for i in range(df.shape[0]):\n",
    "            station_data = []\n",
    "            station_data.append(round(df.iloc[i, 2],2))#lon\n",
    "            station_data.append(round(df.iloc[i, 1],2))#lat\n",
    "            value = round(df.iloc[i, 3],2)\n",
    "            if value!=-9999:\n",
    "                station_data.append(value)\n",
    "                data_canvas['station_list'].append(df.iloc[i,0])\n",
    "                data_canvas['station'].append(station_data)\n",
    "        canvas_data = data_canvas\n",
    "        return canvas_data\n",
    "    def return_ec_data(self):\n",
    "        # 数据---文档\n",
    "        test_time = '2022041700'\n",
    "        file_path = \"/home/workspace/Data/My_Git/\" + test_time + \"/\"\n",
    "        # 文件--数据\n",
    "        conn = pymysql.connect(\n",
    "            host = self.server, \n",
    "            port = self.port,\n",
    "            user = self.user, \n",
    "            password = self.password,\n",
    "            database = self.database)\n",
    "        sql_location = f'''\n",
    "            select IIiii,lat,lon from TAB_StationInfo\n",
    "            where (IIiii in  {self.station} )     \n",
    "        '''\n",
    "        df = pd.read_sql(sql_location, con=conn)\n",
    "        # 查询ec数据\n",
    "        files = os.listdir(file_path)  \n",
    "        fstart = xr.open_dataset(file_path + files[int(self.start)])\n",
    "        tp_start = fstart.tp\n",
    "        fend = xr.open_dataset(file_path + files[int(self.end)])\n",
    "        tp_end = fend.tp \n",
    "        tp = tp_end.data - tp_start.data\n",
    "        # 输出数据\n",
    "        data_canvas = {\n",
    "            \"station_list\": [],\n",
    "            \"station\": []\n",
    "        }\n",
    "        for i in range(df.shape[0]):\n",
    "            station_data = []\n",
    "            \n",
    "            station_data.append(round(df.iloc[i, 2],2))#lon\n",
    "            station_data.append(round(df.iloc[i, 1],2))#lat\n",
    "            # 求数据之差\n",
    "            tp0 = tp_end.sel(lonS=round(df.iloc[i, 2],2), latS=round(df.iloc[i, 1],2),method='nearest').data.tolist()[0]\n",
    "            print(type(tp0))\n",
    "            tp1 = tp_start.sel(lonS=round(df.iloc[i, 2],2), latS=round(df.iloc[i, 1],2),method='nearest').data[0]\n",
    "            value = round((tp0-tp1),2)\n",
    "            if not np.isnan(value):\n",
    "                station_data.append(value)\n",
    "                data_canvas['station_list'].append(df.iloc[i,0])\n",
    "                data_canvas['station'].append(station_data)\n",
    "        canvas_data = data_canvas\n",
    "        return canvas_data\n",
    "    def return_data(self):\n",
    "        if self.type == \"zdz\":\n",
    "            canvas_data = self.return_zdz_data()\n",
    "        else:\n",
    "            canvas_data = self.return_ec_data()\n",
    "        return canvas_data\n",
    "\n",
    "# zdz    \n",
    "#start_time,end_time,select_type = \"2019-03-10 20:00\",\"2019-03-15 20:00\",\"zdz\"\n",
    "# ec\n",
    "start_time,end_time,select_type = 1,25,\"ec\"\n",
    "sql_worker = sql_plot(start_time,end_time,select_type)\n",
    "data = sql_worker.return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'station_list': [58559,\n",
       "  58568,\n",
       "  58652,\n",
       "  58653,\n",
       "  58660,\n",
       "  58661,\n",
       "  58662,\n",
       "  58663,\n",
       "  58664,\n",
       "  58665,\n",
       "  58666,\n",
       "  58667,\n",
       "  58668,\n",
       "  58669,\n",
       "  'K8201',\n",
       "  'K8217',\n",
       "  'K8282',\n",
       "  'K8301',\n",
       "  'K8413',\n",
       "  'K8505',\n",
       "  'K8609',\n",
       "  'K8611',\n",
       "  'K8705',\n",
       "  'K8706',\n",
       "  'K8818',\n",
       "  'K8821',\n",
       "  'K8903',\n",
       "  'K8910'],\n",
       " 'station': [[120.97, 29.15, 21.4],\n",
       "  [121.38, 29.12, 22.3],\n",
       "  [120.72, 28.87, 19.1],\n",
       "  [120.92, 28.81, 22.5],\n",
       "  [121.19, 28.87, 24.0],\n",
       "  [121.51, 28.66, 23.9],\n",
       "  [121.71, 29.01, 28.7],\n",
       "  [121.92, 28.72, 20.3],\n",
       "  [121.36, 28.37, 31.6],\n",
       "  [121.42, 28.62, 25.5],\n",
       "  [121.9, 28.45, 10.0],\n",
       "  [121.27, 28.08, 18.7],\n",
       "  [121.52, 28.1, 21.1],\n",
       "  [121.62, 28.26, 23.9],\n",
       "  [121.28, 28.65, 26.8],\n",
       "  [121.17, 28.63, 24.9],\n",
       "  [120.98, 28.59, 24.3],\n",
       "  [121.35, 28.58, 29.3],\n",
       "  [121.56, 28.45, 27.8],\n",
       "  [121.24, 28.13, 29.6],\n",
       "  [121.45, 28.85, 28.9],\n",
       "  [121.64, 28.71, 28.3],\n",
       "  [120.79, 29.05, 0.6],\n",
       "  [121.0, 29.07, 23.7],\n",
       "  [121.31, 29.0, 27.9],\n",
       "  [121.58, 28.93, 30.8],\n",
       "  [120.79, 28.72, 20.0],\n",
       "  [120.34, 28.7, 21.7]]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ecfine.I2022041700.000.F2022041700.nc', 'ecfine.I2022041700.003.F2022041703.nc', 'ecfine.I2022041700.006.F2022041706.nc', 'ecfine.I2022041700.009.F2022041709.nc', 'ecfine.I2022041700.012.F2022041712.nc', 'ecfine.I2022041700.015.F2022041715.nc', 'ecfine.I2022041700.018.F2022041718.nc', 'ecfine.I2022041700.021.F2022041721.nc', 'ecfine.I2022041700.024.F2022041800.nc', 'ecfine.I2022041700.027.F2022041803.nc', 'ecfine.I2022041700.030.F2022041806.nc', 'ecfine.I2022041700.033.F2022041809.nc', 'ecfine.I2022041700.036.F2022041812.nc', 'ecfine.I2022041700.039.F2022041815.nc', 'ecfine.I2022041700.042.F2022041818.nc', 'ecfine.I2022041700.045.F2022041821.nc', 'ecfine.I2022041700.048.F2022041900.nc', 'ecfine.I2022041700.051.F2022041903.nc', 'ecfine.I2022041700.054.F2022041906.nc', 'ecfine.I2022041700.057.F2022041909.nc', 'ecfine.I2022041700.060.F2022041912.nc', 'ecfine.I2022041700.063.F2022041915.nc', 'ecfine.I2022041700.066.F2022041918.nc', 'ecfine.I2022041700.069.F2022041921.nc', 'ecfine.I2022041700.072.F2022042000.nc', 'ecfine.I2022041700.078.F2022042006.nc', 'ecfine.I2022041700.084.F2022042012.nc', 'ecfine.I2022041700.090.F2022042018.nc', 'ecfine.I2022041700.096.F2022042100.nc', 'ecfine.I2022041700.102.F2022042106.nc', 'ecfine.I2022041700.108.F2022042112.nc', 'ecfine.I2022041700.114.F2022042118.nc', 'ecfine.I2022041700.120.F2022042200.nc', 'ecfine.I2022041700.126.F2022042206.nc', 'ecfine.I2022041700.132.F2022042212.nc', 'ecfine.I2022041700.138.F2022042218.nc', 'ecfine.I2022041700.144.F2022042300.nc', 'ecfine.I2022041700.150.F2022042306.nc', 'ecfine.I2022041700.156.F2022042312.nc', 'ecfine.I2022041700.162.F2022042318.nc', 'ecfine.I2022041700.168.F2022042400.nc', 'ecfine.I2022041700.174.F2022042406.nc', 'ecfine.I2022041700.180.F2022042412.nc', 'ecfine.I2022041700.186.F2022042418.nc', 'ecfine.I2022041700.192.F2022042500.nc', 'ecfine.I2022041700.198.F2022042506.nc', 'ecfine.I2022041700.204.F2022042512.nc', 'ecfine.I2022041700.210.F2022042518.nc', 'ecfine.I2022041700.216.F2022042600.nc', 'ecfine.I2022041700.222.F2022042606.nc', 'ecfine.I2022041700.228.F2022042612.nc', 'ecfine.I2022041700.234.F2022042618.nc', 'ecfine.I2022041700.240.F2022042700.nc']\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import os\n",
    "import xarray as xr\n",
    "test_time = '2022041700'\n",
    "file_path = \"/home/workspace/Data/My_Git/\" + test_time + \"/\"\n",
    "files = os.listdir(file_path)  \n",
    "print(files)\n",
    "fstart = xr.open_dataset(file_path + files[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql \n",
    "import pandas as pd\n",
    "\n",
    "## 连接数据库\n",
    "server = '172.21.158.201'    # 连接服务器地址\n",
    "user = 'down'# 连接帐号\n",
    "password = 'downx'# 连接密码\n",
    "conn = pymssql.connect(server, user, password, 'ZJSZDZDB')  #获取连接\n",
    "\n",
    "## 以查询区域站数据为例 ---- 以下是说明（国家站对应TAB_Mws2022改为TAB_Aws2022）\n",
    "# RR是小时降水，R01是第一分钟的降水,以此类推\n",
    "# TAB_Mws2022是对应每年的数据表，具体2022可以更改对应年份------》“from TAB_Mws2022 as a left join TAB_StationInfo”\n",
    "# TAB_Mws2022是2022年区域站的数据，若想查询国家站数据则需要改为TAB_Aws2022\n",
    "# tTime是时间，查询对应时间就修改成对应的时段-------》'tTime between '2022-01-10 20:00' and '2022-02-10 08:00''\n",
    "sql_M_location = 'select RR,R01,R02,R03,R04,R05,R06,R07,R08,R09,R10\\\n",
    "    ,R11,R12,R13,R14,R15,R16,R17,R18,R19,R20,\\\n",
    "    R21,R22,R23,R24,R25,R26,R27,R28,R29,R30,\\\n",
    "    R31,R32,R33,R34,R35,R36,R37,R38,R39,R40,\\\n",
    "    R41,R42,R43,R44,R45,R46,R47,R48,R49,R50,\\\n",
    "    R51,R52,R53,R54,R55,R56,R57,R58,R59,R60 \\\n",
    "    from TAB_Mws2022 as a left join TAB_StationInfo as b on a.IIiii=b.IIiii where\\\n",
    "    (b.IIiii in (select IIiii from TAB_StationInfo where(City = '台州') and\\\n",
    "    tTime between '2022-01-10 20:00' and '2022-02-10 08:00'))'\n",
    "\n",
    "df_M_location = pd.read_sql(sql_M_location , con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RR</th>\n",
       "      <th>R01</th>\n",
       "      <th>R02</th>\n",
       "      <th>R03</th>\n",
       "      <th>R04</th>\n",
       "      <th>R05</th>\n",
       "      <th>R06</th>\n",
       "      <th>R07</th>\n",
       "      <th>R08</th>\n",
       "      <th>R09</th>\n",
       "      <th>...</th>\n",
       "      <th>R51</th>\n",
       "      <th>R52</th>\n",
       "      <th>R53</th>\n",
       "      <th>R54</th>\n",
       "      <th>R55</th>\n",
       "      <th>R56</th>\n",
       "      <th>R57</th>\n",
       "      <th>R58</th>\n",
       "      <th>R59</th>\n",
       "      <th>R60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338439</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338440</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338441</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338442</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338443</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338444 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RR  R01  R02  R03  R04  R05  R06  R07  R08  R09  ...  R51  R52  R53  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...     ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "338439   1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "338440   0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "338441   0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "338442   2    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "338443   0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "        R54  R55  R56  R57  R58  R59  R60  \n",
       "0         0    0    0    0    0    0    0  \n",
       "1         0    0    0    0    0    0    0  \n",
       "2         0    0    0    0    0    0    0  \n",
       "3         0    0    0    0    0    0    0  \n",
       "4         0    0    0    0    0    0    0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "338439    0    0    0    0    0    0    0  \n",
       "338440    0    0    0    0    0    0    0  \n",
       "338441    0    0    0    0    0    0    0  \n",
       "338442    0    0    0    0    0    0    0  \n",
       "338443    0    0    0    0    0    0    0  \n",
       "\n",
       "[338444 rows x 61 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_M_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# coding=UTF-8\n",
    "import gevent\n",
    "from math import isnan\n",
    "import numpy as np\n",
    "#import modin.pandas as pd \n",
    "import pandas as pd\n",
    "import time\n",
    "import netCDF4 \n",
    "# import h5netcdf.legacyapi as netCDF4\n",
    "import h5py\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import shapefile\n",
    "import matplotlib as mpl\n",
    "import xarray as xr\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import netCDF4 as nc\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "from ncmaps import Cmaps\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import json\n",
    "import math\n",
    "from scipy.interpolate import griddata\n",
    "from math import ceil, floor\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "import os\n",
    "from datetime import *\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from matplotlib.font_manager import FontProperties  # 步骤一\n",
    "from rasterio import features\n",
    "import pymysql\n",
    "import pymssql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import redis\n",
    "import datetime as dtt\n",
    "\n",
    "class nlcmap(LinearSegmentedColormap):\n",
    "    \"\"\"A nonlinear colormap\"\"\"\n",
    "\n",
    "    name = 'nlcmap'\n",
    "\n",
    "    def __init__(self, cmap, levels):\n",
    "        self.cmap = cmap\n",
    "        self.monochrome = self.cmap.monochrome\n",
    "        self.levels = np.asarray(levels, dtype='float64')\n",
    "        self._x = self.levels/ self.levels.max()\n",
    "        self.levmax = self.levels.max()\n",
    "        self.levmin = self.levels.min()\n",
    "        self._y = np.linspace(self.levmin, self.levmax, len(self.levels))\n",
    "\n",
    "    def __call__(self, xi, alpha=1.0, **kw):\n",
    "        yi = np.interp(xi, self._x, self._y)\n",
    "        return self.cmap(yi/self.levmax, alpha)\n",
    "class station_plot:\n",
    "    def __init__(self):\n",
    "        self.conn = pymysql.connect(host=\"127.0.0.1\",port=3306,user=\"root\",passwd=\"051219\",db=\"ZJSZDZDB\")\n",
    "        self.shp_path = \"shpfile/country/\"\n",
    "    # 外部函数\n",
    "    def colormap(self,plot_value,color_label):\n",
    "        '''色标的自定义'''\n",
    "        plt.rcParams['axes.facecolor']='snow'\n",
    "        # 降水\n",
    "        if plot_value==\"rain\":\n",
    "            if color_label ==\"rain_24hours\":\n",
    "                colorslist = ['#FFFFFF','#A6F28f','#3DBA3D',\"#61B8FF\",\"#0000E1\",\"#FA00FA\",\"#800040\"]# 24降水\n",
    "                levels = [0,1,10,25,50,100,250,1000]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels)\n",
    "            elif color_label ==\"rain_12hours\":\n",
    "                colorslist = ['#FFFFFF','#A6F28f','#3DBA3D',\"#61B8FF\",\"#0000E1\",\"#FA00FA\",\"#800040\"]# 12降水\n",
    "                levels = [0,1,5,15,30,70,140,250]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels)\n",
    "            elif color_label ==\"rain_06hours\":\n",
    "                colorslist = ['#FFFFFF','#A6F28f','#3DBA3D',\"#61B8FF\",\"#0000E1\",\"#FA00FA\",\"#800040\"]# 06降水\n",
    "                levels = [0,1,4,13,25,60,120,250]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels)\n",
    "            elif color_label ==\"rain_03hours\":\n",
    "                colorslist = ['#FFFFFF','#A6F28f','#3DBA3D',\"#61B8FF\",\"#0000E1\",\"#FA00FA\",\"#800040\"]# 03降水\n",
    "                levels = [0,1,3,10,20,50,70,150]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels)\n",
    "            elif color_label ==\"rain_01hours\":\n",
    "                colorslist = ['#FFFFFF','#A6F28f','#3DBA3D',\"#61B8FF\",\"#0000E1\",\"#FA00FA\",\"#800040\"]# 01降水\n",
    "                levels = [0,1,2,7,15,40,50,100]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels)\n",
    "        elif plot_value==\"tmax\" or plot_value==\"tmin\":\n",
    "            if color_label ==\"temp_normal\":\n",
    "                #colorslist = ['#1F1FFF',\"#3B3BFF\",\"#5757FF\",\"#7272FF\",\"#8F8FFF\",\"#ABABFF\",\"#C7C7FF\",\"#E3E3FF\",\"#FDFC8B\",\"#F8E08B\",\"#F3C36F\",\"#EFA76E\",\"#EC8A51\",\"#F31717\"]# 气温\n",
    "                #colornum = len(colorslist)\n",
    "                level = list(np.linspace(self.min-1, self.max+1, num=14, endpoint=True, retstep=False, dtype=None))\n",
    "                levels = [round(i,1) for i in level]\n",
    "                cmap_nonlin = 'seismic'#'coolwarm'#\n",
    "            elif color_label ==\"temp_high\":\n",
    "                level = list(np.linspace(self.min-1, self.max+1, num=14, endpoint=True, retstep=False, dtype=None))\n",
    "                levels = [round(i,1) for i in level]\n",
    "                cmap_nonlin = 'Reds'\n",
    "            elif color_label ==\"temp_low\":\n",
    "                level = list(np.linspace(self.min-1, self.max+1, num=14, endpoint=True, retstep=False, dtype=None))\n",
    "                levels = [round(i,1) for i in level]\n",
    "                cmap_nonlin = 'Blues_r'\n",
    "        elif plot_value==\"wind\":\n",
    "            if color_label ==\"wind_normal\":\n",
    "                colorslist = ['#FFFFFF','#A6F28f','#3DBA3D',\"#61B8FF\",\"#0000E1\",\"#FA00FA\",\"#800040\"]# 风力\n",
    "                levels = [0,1,10,15,25,50,100,250]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels) \n",
    "            elif color_label ==\"wind_other\":\n",
    "                colorslist = ['#FFFFFF','#A6F28f','#3DBA3D',\"#61B8FF\",\"#0000E1\",\"#FA00FA\",\"#800040\"]# 风力其他\n",
    "                levels = [0,1,10,15,25,50,100,250]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels)\n",
    "        elif plot_value==\"view\":\n",
    "            if color_label ==\"view_normal\":\n",
    "                colorslist = ['#A93434','#FF9600','#FFFD37',\"#55FF37\",\"#ABF3D3\",\"#5EC6EB\",\"#B1F1EF\"]# 能见度\n",
    "                levels = [0,50,200,500,1000,1500,3000,20000]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels) \n",
    "            elif color_label ==\"view_other\":\n",
    "                colorslist = ['#FFFFFF','#FF9600','#3DBA3D',\"#61B8FF\",\"#0000E1\",\"#FA00FA\",\"#800040\"]# 能见度\n",
    "                levels = [0,1,10,15,25,50,100,250]\n",
    "                cmaps = LinearSegmentedColormap.from_list('mylist',colorslist,N=7)\n",
    "                cmap_nonlin = nlcmap(cmaps, levels)             \n",
    "        return cmap_nonlin ,levels\n",
    "    def city_shp(self,data_xr):\n",
    "        shp_da = self.add_shape_coord_from_data_array(data_xr,self.shp_path+\"taizhou.shp\", \"country\")\n",
    "        awash_da = shp_da.where(shp_da.country<7, other=np.nan)\n",
    "        return awash_da\n",
    "    def transform_from_latlon(self,lat, lon):\n",
    "        lat = np.asarray(lat)\n",
    "        lon = np.asarray(lon)\n",
    "        trans = Affine.translation(lon[0], lat[0])\n",
    "        scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n",
    "        return trans * scale    \n",
    "    def rasterize(self,shapes, coords, latitude='lat', longitude='lon',fill=np.nan, **kwargs):\n",
    "        transform = self.transform_from_latlon(coords[latitude], coords[longitude])\n",
    "        out_shape = (len(coords[latitude]), len(coords[longitude]))\n",
    "        raster = features.rasterize(shapes, out_shape=out_shape,\n",
    "                                fill=fill, transform=transform,\n",
    "                                dtype=float, **kwargs)\n",
    "        spatial_coords = {latitude: coords[latitude], longitude: coords[longitude]}\n",
    "        return xr.DataArray(raster, coords=spatial_coords, dims=(latitude, longitude))\n",
    "    def add_shape_coord_from_data_array(self,xr_da, shp_path, coord_name):   \n",
    "        shp_gpd = gpd.read_file(shp_path)\n",
    "        shapes = [(shape, n) for n, shape in enumerate(shp_gpd.geometry)]\n",
    "        xr_da[coord_name] = self.rasterize(shapes, xr_da.coords, longitude='lon', latitude='lat')\n",
    "        return xr_da\n",
    "    def basemask(self,cs, ax, map, shpfile):\n",
    "        sf = shapefile.Reader(shpfile)\n",
    "        vertices = []\n",
    "        codes = []\n",
    "        for shape_rec in sf.shapeRecords():\n",
    "            if shape_rec.record[0]:  \n",
    "                pts = shape_rec.shape.points\n",
    "                prt = list(shape_rec.shape.parts) + [len(pts)]\n",
    "                for i in range(len(prt) - 1):\n",
    "                    for j in range(prt[i], prt[i+1]):\n",
    "                        vertices.append(map(pts[j][0], pts[j][1]))\n",
    "                    codes += [Path.MOVETO]\n",
    "                    codes += [Path.LINETO] * (prt[i+1] - prt[i] -2)\n",
    "                    codes += [Path.CLOSEPOLY]\n",
    "                clip = Path(vertices, codes)\n",
    "                clip = PathPatch(clip, transform = ax.transData)    \n",
    "        for contour in cs.collections:\n",
    "            contour.set_clip_path(clip)    \n",
    "    # 内部函数\n",
    "    def get_sql_data(self,start,end):      \n",
    "        '''sql 获取数据'''\n",
    "        tables = ['TAB_Aws2019','TAB_Mws2019']\n",
    "        data_list = []\n",
    "        sqltall = \"\"\"select ta.IIiii,max(station.lat) as lat,max(station.lon) as lon,max(station.StationName) as StationName,\n",
    "        max(station.City) as City,max(station.County) as County,max(station.Town) as Town,max(station.Village) as Village,max(station.Country) as Country, \n",
    "        max(fFy*1000+dFy) as fff ,min(VV) as view,max(T) as tmax,min(T) as tmin ,sum(RR) as rain,max(fFy) as wind\n",
    "        from {table} as ta inner join TAB_StationInfo as station on ta.IIIII=station.IIiii  \n",
    "        where (tTime between '{start}' and '{end}' and station.lon>119 and station.lon<122 and station.lat>27.5 and station.lat<29.5 ) \n",
    "        group by ta.IIiii\"\"\"\n",
    "        for table in tables: \n",
    "            rsql = sqltall.format(start=start,end=end,table=table)\n",
    "            data = pd.read_sql(rsql , con=self.conn)\n",
    "            data_list.append(data)\n",
    "        station_all = pd.concat(data_list)\n",
    "        station_all['fff'] = station_all['fff'].values.astype(str)\n",
    "        station_all['dFy'] = station_all['fff'].str.slice(-3)\n",
    "        station_all[\"dFy\"] = pd.to_numeric(station_all[\"dFy\"])\n",
    "        return station_all\n",
    "    def extra_download(self,start,end,city,country):\n",
    "        station_all = self.get_sql_data(start,end)\n",
    "        station_all['lock'] = \"true\"\n",
    "        if country==\"all\":\n",
    "            country = city\n",
    "            data = station_all[station_all['City']==city]\n",
    "        else:\n",
    "            country = country\n",
    "            data = station_all[station_all['County']==country]\n",
    "        output = data.to_json(orient='records',force_ascii=False)\n",
    "        return output\n",
    "    def get_plot_data(self,city,country,plot_data,plot_value):\n",
    "        '''解析前段获取的数据'''\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        for i in range(len(plot_data)):\n",
    "            if plot_data[i][plot_value]!=-9999.0:\n",
    "                x.append(plot_data[i]['lon'])\n",
    "                y.append(plot_data[i]['lat'])\n",
    "                z.append(plot_data[i][plot_value]/10)\n",
    "        lat = np.array(y)\n",
    "        lon = np.array(x)\n",
    "        Zi = np.array(z)\n",
    "        data_max = max(Zi)\n",
    "        data_min = min(Zi)\n",
    "        np.set_printoptions(precision = 2)\n",
    "        x = np.arange(120.0,122.0,0.05)\n",
    "        y = np.arange(27.8,29.5,0.05)\n",
    "        nx0 =len(x)\n",
    "        ny0 =len(y)\n",
    "        X, Y = np.meshgrid(x, y)#100*100\n",
    "        P = np.array([X.flatten(), Y.flatten() ]).transpose()    \n",
    "        Pi =  np.array([lon, lat ]).transpose()\n",
    "        Z_linear = griddata(Pi, Zi, P, method = \"nearest\").reshape([ny0,nx0])\n",
    "        data_xr = xr.DataArray(Z_linear, coords=[ y,x], dims=[\"lat\", \"lon\"])\n",
    "        return data_xr\n",
    "    def plot(self,start,end,city,country,plot_data,plot_value,color_label):\n",
    "        data_xr = self.get_plot_data(city,country,plot_data,plot_value)\n",
    "        # 平滑\n",
    "        #data_xr = scipy.ndimage.zoom(data_xr, 3)\n",
    "        # ##########色标和大小#############################\n",
    "        cmaps ,levels = self.colormap(plot_value,color_label)\n",
    "        fig = plt.figure(figsize=[10,10]) \n",
    "        ax = fig.add_subplot(111)\n",
    "        awash_da = self.city_shp(data_xr)\n",
    "        lat = data_xr.lat\n",
    "        lon = data_xr.lon\n",
    "        m = Basemap(llcrnrlon=120.2,\n",
    "            llcrnrlat=27.8,\n",
    "            urcrnrlon=122,\n",
    "            urcrnrlat=29.5,\n",
    "            resolution = None, \n",
    "            projection = 'cyl')\n",
    "        lons, lats = np.meshgrid(lon, lat)\n",
    "        cs =m.contourf(lons,lats,data_xr,ax=ax, cmap=cmaps,levels =levels,add_labels=True)\n",
    "        ##########标题#############################\n",
    "        font = FontProperties(fname=\"simkai.ttf\", size=14)\n",
    "        label  = start + \" 至 \" + end + \"   \"  + \"累积雨量\"\n",
    "        plt.text(120.2,29.4, label,fontsize=15, fontproperties=font)\n",
    "        ##########标题#############################\n",
    "        m.readshapefile(self.shp_path + 'taizhou','taizhou',color='k',linewidth=1.2)\n",
    "        plt.axis('off')\n",
    "        # 在图上绘制色标\n",
    "        rect1 = [0.35, 0.25, 0.03, 0.12]         \n",
    "        ax2 = plt.axes(rect1,frameon='False')\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.spines['bottom'].set_visible(False)\n",
    "        ax2.spines['left'].set_visible(False)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        m.colorbar(cs, location='right', size='30%', pad=\"-100%\",ax = ax2)\n",
    "        self.basemask(cs, ax, m, self.shp_path+'taizhou') \n",
    "        buffer = BytesIO()\n",
    "        plt.savefig(buffer,bbox_inches='tight')  \n",
    "        plot_img = buffer.getvalue()\n",
    "        imb = base64.b64encode(plot_img) \n",
    "        ims = imb.decode()\n",
    "        imd = \"data:image/png;base64,\"+ims\n",
    "        return imd        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "plot_data = [{\"lat\":28.6,\"lon\":121.5,\"rain\":-9999},{\"lat\":28.6,\"lon\":121.3,\"rain\":2000}]\n",
    "start = '2019-08-08 09:00:00'  \n",
    "end ='2019-08-09 09:00:00'\n",
    "worker = station_plot()\n",
    "city = \"台州\"\n",
    "country = \"all\"\n",
    "color_label = \"rain_24hours\"\n",
    "# data = worker.extra_download(start,end,city,country)\n",
    "plot_value = \"rain\"\n",
    "data = worker.plot(start,end,city,country,plot_data,plot_value,color_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
