{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据优化2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import isnan\n",
    "\n",
    "class sql_data:\n",
    "    def __init__(self, sql):\n",
    "        self.sql = sql# 传进来的参数\n",
    "        station_Mws = pd.read_csv(\"Mws_15.csv\")\n",
    "        station_Aws = pd.read_csv(\"Aws_15.csv\")\n",
    "        self.station_all = pd.concat([station_Aws,station_Mws])\n",
    "        # 数据\n",
    "        self.grouped_county = self.station_all.groupby('county')\n",
    "        self.grouped_IIiii = self.station_all.groupby('IIiii')\n",
    "        self.timecounts = len(self.grouped_IIiii.get_group(58660)['tTime'])\n",
    "        # 测试数据\n",
    "        print(self.timecounts)\n",
    "    def comput_county(self):\n",
    "        '计算面最大雨强、累计降水、最高、最低气温'\n",
    "        self.station_county_comput = []\n",
    "        for i in self.grouped_county.size().index:  \n",
    "            data= self.grouped_county.get_group(i)\n",
    "            data['VV'].replace(-9999,np.nan,inplace=True)\n",
    "            data['RR'].replace(-9999,np.nan,inplace=True)\n",
    "            data['Tn'].replace(-9999,np.nan,inplace=True)\n",
    "            data['Tx'].replace(-9999,np.nan,inplace=True)\n",
    "            dic = {}\n",
    "            dic['county'] = str(i)\n",
    "            dic['RR'] = data['RR'].mean()*self.timecounts/10.0\n",
    "            dic['RMax'] = data['RR'].max()/10.0\n",
    "            dic['Tx'] = data['Tx'].max()/10.0\n",
    "            dic['Tn'] = data['Tn'].min()/10.0 \n",
    "#             print(dic)\n",
    "            self.station_county_comput.append(dic)\n",
    "        tmp_max_County = []\n",
    "        tmp_min_County = []\n",
    "        RR_County = []\n",
    "        for i in self.station_county_comput:\n",
    "            tmp_max_County.append({\"name\":i['county'],\"value\":i['Tx']})\n",
    "            tmp_min_County.append({\"name\":i['county'],\"value\":i['Tn']})\n",
    "            RR_County.append({\"name\":i['county'],\"value\":i['RR']})\n",
    "        return RR_County,tmp_max_County,tmp_min_County\n",
    "\n",
    "    def comput_IIiii(self):\n",
    "        self.station_dot_comput = {} \n",
    "        lat = []\n",
    "        lon = []\n",
    "        tx = []\n",
    "        tn = []\n",
    "        rr = [] \n",
    "        rx = []\n",
    "        county = []\n",
    "        name = []\n",
    "        vv = []\n",
    "        town = []\n",
    "        vv_min = \" \"#{\"name\":[],\"value\":0.0}\n",
    "        vv_value = 1000.0\n",
    "        station_RR_small = 0.0\n",
    "        station_RR_mid = 0.0\n",
    "        station_RR_big = 0.0\n",
    "        station_RR_huge = 0.0\n",
    "        station_RR_bighuge = 0.0\n",
    "        station_RR_more = 0.0\n",
    "        station_VV_small = 0.0\n",
    "        station_VV_mid = 0.0\n",
    "        station_VV_big = 0.0\n",
    "        station_VV_huge = 0.0\n",
    "        station_VV_more = 0.0\n",
    "        station_wind7 = 0.0\n",
    "        station_wind8 = 0.0\n",
    "        station_wind9 = 0.0\n",
    "        station_wind10 = 0.0\n",
    "        station_wind11 = 0.0\n",
    "        station_wind12 = 0.0\n",
    "        station_wind13 = 0.0\n",
    "        station_wind14 = 0.0\n",
    "        station_wind15 = 0.0\n",
    "        station_wind16 = 0.0\n",
    "        station_wind17 = 0.0\n",
    "\n",
    "        station_vv = []\n",
    "        VV_scatter_list = []\n",
    "        # 指标站数据\n",
    "        fFy_name_list = []\n",
    "        dFy_scater_list = []\n",
    "        fFy_scater_list = []\n",
    "        # 温度站点\n",
    "        temp_event_list = []\n",
    "        nation_station = ['58660','58666','K8505','K8206','58665','58559','58655','K8271','58662','58653']\n",
    "        temp_scatter_list = ['58559','K8705','K8706','58652','K8903','58568','K8818','58662','K8821','58660',\n",
    "                             '58653','K8609','K8505','58667','58664','K8413','58655','K8282','K8217','K8201','K8301','58665']\n",
    "        for i in self.grouped_IIiii.size().index:\n",
    "            data= self.grouped_IIiii.get_group(i)\n",
    "            #print(data)\n",
    "            data['VV'].replace(-9999,np.nan,inplace=True)\n",
    "            data['RR'].replace(-9999,np.nan,inplace=True)\n",
    "            data['Tn'].replace(-9999,np.nan,inplace=True)\n",
    "            data['Tx'].replace(-9999,np.nan,inplace=True)\n",
    "#             data['fFy'].replace(-9999,np.nan,inplace=True)\n",
    "            dic = {}\n",
    "            dic['IIiii'] = data['IIiii'].iloc[0]\n",
    "            dic['tTime'] = data['tTime'].tolist()\n",
    "            dic['StationName'] = data['StationName'].iloc[0]\n",
    "            dic['county'] = data['county'].iloc[0]\n",
    "            dic['lat'] = data['lat'].iloc[0]\n",
    "            dic['lon'] = data['lon'].iloc[0]\n",
    "            dic['Town'] = data['Town'].iloc[0]\n",
    "            dic['fFy'] = data['fFy'].max()           \n",
    "            dic['dFy'] = data[data['fFy']== data['fFy'].max()]['dFy'].iloc[0]\n",
    "            dic['T'] = data['T'].tolist()\n",
    "            dic['VList'] = data['VV'].tolist()\n",
    "            dic['fFyList'] = data['fFy'].tolist()\n",
    "            dic['dFyList'] = data['dFy'].tolist()\n",
    "            dic['Tx'] = data['Tx'].max()/10.0\n",
    "                        \n",
    "            dic['Tn'] = data['Tn'].min()/10.0\n",
    "            if not isnan(data['VV'].min()):\n",
    "                #统计能见度自动站名称\n",
    "                station_vv.append(data['IIiii'].iloc[0])\n",
    "                if data['VV'].min() < vv_value:\n",
    "#                     print(data['IIiii'].iloc[0])\n",
    "                    vv_min=  str(data['IIiii'].iloc[0])\n",
    "                    vv_value = data['VV'].min()\n",
    "            dic['VV'] = data['VV'].min()\n",
    "            dic['RR'] = data['RR'].sum()\n",
    "            dic['RMax'] = data['RR'].max()\n",
    "            # 降水分级别\n",
    "            if not isnan(data['RR'].sum()):\n",
    "                value_rsum = data['RR'].sum()\n",
    "                if value_rsum >=0 and value_rsum <10:\n",
    "                    station_RR_small =  station_RR_small +1   \n",
    "                elif value_rsum >=10 and value_rsum <25:\n",
    "                    station_RR_mid =  station_RR_mid+1   \n",
    "                elif value_rsum >=25 and value_rsum <50:\n",
    "                    station_RR_big =  station_RR_big +1   \n",
    "                elif value_rsum >=50 and value_rsum <100:\n",
    "                    station_RR_huge =  station_RR_huge+1   \n",
    "                elif value_rsum >=100 and value_rsum <250:\n",
    "                    station_RR_RR_bighuge =  station_RR_bighuge+1 \n",
    "                else:\n",
    "                    station_RR_more =  station_RR_more+1\n",
    "            # 气温警报分级统计\n",
    "            if dic['Tx']>35.0 or dic['Tn']<3.0 :\n",
    "                temp_event_list.append(str(data['IIiii'].iloc[0]))\n",
    "            # 能见度分级别  \n",
    "            if not isnan(data['VV'].min()):\n",
    "                VV_scatter_list.append(data['IIiii'].iloc[0])\n",
    "                value_VV = data['VV'].min()\n",
    "#                 print(value_VV)\n",
    "                if value_VV >=0 and value_VV <50:\n",
    "                    station_VV_small =  station_VV_small +1   \n",
    "                elif value_VV >=50 and value_VV <200:\n",
    "                    station_VV_mid =  station_VV_mid+1   \n",
    "                elif value_VV >=200 and value_VV <500:\n",
    "                    station_VV_big =  station_VV_big +1   \n",
    "                elif value_VV >=500 and value_VV <5000:\n",
    "                    station_VV_huge =  station_VV_huge+1   \n",
    "                else: \n",
    "                    station_VV_more =  station_VV_more+1 \n",
    "            # 大风分级  \n",
    "            if not isnan(data['fFy'].max()):\n",
    "                if data['fFy'].max() > 138:\n",
    "                    fFy_scater_list.append(str(data['IIiii'].iloc[0]))\n",
    "                fFy_data =  data['fFy'].max()     \n",
    "                if fFy_data> 13.8 and fFy_data<=17.1 :\n",
    "                    station_wind7 = station_wind7 +1\n",
    "                elif fFy_data > 17.1 and fFy_data <=20.7 :\n",
    "                    station_wind8 = station_wind8 +1\n",
    "                elif fFy_data > 20.7 and fFy_data <=24.4 :\n",
    "                    station_wind9 = station_wind9 +1\n",
    "                elif fFy_data > 24.4 and fFy_data <=28.4 :\n",
    "                    station_wind10 = station_wind10 +1\n",
    "                elif fFy_data > 28.4 and fFy_data <=32.6 :\n",
    "                    station_wind11 = station_wind11 +1\n",
    "                elif fFy_data > 32.6 and fFy_data <=36.9 :\n",
    "                    station_wind12 = station_wind12 +1\n",
    "                elif fFy_data > 36.9 and fFy_data <=41.4 :\n",
    "                    station_wind13 = station_wind13 +1\n",
    "                elif fFy_data > 41.4 and fFy_data <=46.1 :\n",
    "                    station_wind14 = station_wind14 +1\n",
    "                elif fFy_data > 46.1 and fFy_data <=51.0 :\n",
    "                    station_wind15 = station_wind15 +1\n",
    "                elif fFy_data > 51.0 and fFy_data <=56.1 :\n",
    "                    station_wind16 = station_wind16 +1\n",
    "                else: \n",
    "                    station_wind17 = station_wind17 +1\n",
    "\n",
    "                    \n",
    "            lat.append(data['lat'].iloc[0])\n",
    "            town.append(data['Town'].iloc[0])\n",
    "            lon.append(data['lon'].iloc[0])\n",
    "            county.append(data['county'].iloc[0])\n",
    "            name.append(data['IIiii'].iloc[0])\n",
    "            tx.append(data['Tx'].max()/10.0)\n",
    "            tn.append(data['Tn'].max()/10.0)\n",
    "            rr.append(data['RR'].sum()/10.0)\n",
    "            rx.append(data['RR'].max()/10.0)\n",
    "#             print(dic)\n",
    "            self.station_dot_comput[str(i)] = dic \n",
    "#         print(lat)\n",
    "        #排序数据\n",
    "        rain_max = max(rr)\n",
    "        rain_min = min(rr)\n",
    "        level_rain = np.linspace(start = rain_min, stop = rain_max, num = 9)\n",
    "        print(level_rain)\n",
    "        \n",
    "\n",
    "        data_rx =  pd.DataFrame()\n",
    "        data_rx['name'] = name \n",
    "        data_rx['county'] = county\n",
    "        data_rx['town'] = town\n",
    "        data_rx['rx'] = rx \n",
    "        data_rx['lat'] = lat\n",
    "        data_rx['lon'] = lon\n",
    "        data_rx['index']=data_rx['rx'].rank(ascending=0,method='dense')\n",
    "        data_rr_rx = data_rx.sort_values(by =['rx'],ascending = [False])\n",
    "        RR_rx = []\n",
    "        for row in data_rr_rx.itertuples():\n",
    "            dic_rr = {'index':int(getattr(row, 'index')),'IIiii':str(getattr(row, 'name')),\n",
    "            'county':getattr(row, 'county'),'town':getattr(row, 'town'),'data':getattr(row, 'rx'),\n",
    "            'value':[getattr(row, 'lon'),getattr(row, 'lat'),getattr(row, 'rx')],\n",
    "            'url':\"station/\"+str(getattr(row, 'name'))}\n",
    "            RR_rx.append(dic_rr)\n",
    "\n",
    "        # 按照累计降水进行排序\n",
    "        data_rsum =  pd.DataFrame()\n",
    "        data_rsum['name'] = name \n",
    "        data_rsum['county'] = county\n",
    "        data_rsum['town'] = town\n",
    "        data_rsum['rsum'] = rr \n",
    "        data_rsum['lat'] = lat\n",
    "        data_rsum['lon'] = lon\n",
    "        data_rr_plot = [lat,lon,rr] \n",
    "        data_rsum['index']=data_rsum['rsum'].rank(ascending=0,method='dense')\n",
    "        data_rr_sum = data_rsum.sort_values(by =['rsum'],ascending = [False])\n",
    "        RR_sum = []\n",
    "        for row in data_rr_sum.itertuples():\n",
    "            dic_rr = {'index':int(getattr(row, 'index')),'IIiii':str(getattr(row, 'name')),\n",
    "            'county':getattr(row, 'county'),'town':getattr(row, 'town'),'data':getattr(row, 'rsum'),\n",
    "            'value':[getattr(row, 'lon'),getattr(row, 'lat'),getattr(row, 'rsum')],\n",
    "            'url':\"station/\"+str(getattr(row, 'name'))}\n",
    "            RR_sum.append(dic_rr)\n",
    "#         data_rsum['index'] = [a for i in ]\n",
    "#         print(data_rx.sort_values(by =['rx'],ascending = [False]))\n",
    "        # 最大值对应的站点序列\n",
    "        data_vv = vv_min\n",
    "        #print(\"最低能见度\",data_vv,vv_min)\n",
    "        data_vvmin =  pd.DataFrame()\n",
    "        data_vvmin['tTime']= self.station_dot_comput[data_vv]['tTime']\n",
    "        data_vvmin['VV']= self.station_dot_comput[data_vv]['VList']\n",
    "        #print(\"data:\",data_vvmin)\n",
    "        # 降水分级\n",
    "        # RR_station_rank = [\n",
    "        #     { \"value\": station_RR_small, \"name\": '小雨' },\n",
    "        #     { \"value\": station_RR_mid, \"name\": '中雨' },\n",
    "        #     { \"value\": station_RR_big, \"name\": '大雨' },\n",
    "        #     { \"value\": station_RR_huge, \"name\": '暴雨' },\n",
    "        #     { \"value\": station_RR_bighuge, \"name\": '大暴雨' },\n",
    "        #     { \"value\": station_RR_more, \"name\": '特大暴雨' }\n",
    "        # ]\n",
    "        RR_station_rank = [station_RR_small,station_RR_mid,station_RR_big,station_RR_huge,station_RR_bighuge,station_RR_more]\n",
    "        tmp_station_bar = []\n",
    "        tmp_station_bar.append(['product', '最高气温','最低气温'])\n",
    "        RR_station_bar = []\n",
    "        RR_station_bar.append(['product', '累计降水','最大雨强'])\n",
    "        # 计算指标站nation_station的要素值\n",
    "        for i in nation_station:\n",
    "            tmp_station_bar.append([self.station_dot_comput[i]['StationName'], self.station_dot_comput[i]['Tx'],self.station_dot_comput[i]['Tn']])\n",
    "            RR_station_bar.append([self.station_dot_comput[i]['StationName'], self.station_dot_comput[i]['RR'],self.station_dot_comput[i]['RMax']])\n",
    "  \n",
    "        # 返回站点气温数据\n",
    "        tmp_min_scatter = []\n",
    "        tmp_max_scatter = []\n",
    "        for i in temp_scatter_list:\n",
    "            dic_temp_max = {\"value\":[],\"url\":\"\",}\n",
    "            dic_temp_max['value'].append(self.station_dot_comput[i]['lon'])\n",
    "            dic_temp_max['value'].append(self.station_dot_comput[i]['lat'])\n",
    "            dic_temp_max['value'].append(self.station_dot_comput[i]['Tx'])\n",
    "            dic_temp_max['url'] =\"station/\"+str(self.station_dot_comput[i]['IIiii'])\n",
    "            dic_temp_max['label'] =str(self.station_dot_comput[i]['Tx'])\n",
    "            dic_temp_max['name'] = str(self.station_dot_comput[i]['StationName'])\n",
    "            dic_temp_min = {\"value\":[],\"url\":\"\"}\n",
    "            dic_temp_min['value'].append(self.station_dot_comput[i]['lon'])\n",
    "            dic_temp_min['value'].append(self.station_dot_comput[i]['lat'])\n",
    "            dic_temp_min['value'].append(self.station_dot_comput[i]['Tn'])\n",
    "            dic_temp_min['url'] =\"station/\"+str(self.station_dot_comput[i]['IIiii'])\n",
    "            dic_temp_min['name'] = str(self.station_dot_comput[i]['StationName'])\n",
    "            dic_temp_min['label'] =str(self.station_dot_comput[i]['Tn'])\n",
    "            tmp_max_scatter.append(dic_temp_max)\n",
    "            tmp_min_scatter.append(dic_temp_min)\n",
    "        # 返回气温警报数据\n",
    "        tmp_event_scatter = []\n",
    "        for i in temp_event_list:\n",
    "            tmp_event = {\"value\":[],\"url\":\"\"}\n",
    "            tmp_event['value'].append(self.station_dot_comput[i]['lon'])\n",
    "            tmp_event['value'].append(self.station_dot_comput[i]['lat'])\n",
    "            if self.station_dot_comput[i]['Tx']>350:\n",
    "                tmp_event['value'].append(self.station_dot_comput[i]['Tx'])\n",
    "            elif self.station_dot_comput[i]['Tn']<40:\n",
    "                tmp_event['value'].append(self.station_dot_comput[i]['Tn'])\n",
    "            tmp_event['url'] =\"station/tmp/\"+str(self.station_dot_comput[i]['IIiii'])\n",
    "            tmp_event['name'] = str(self.station_dot_comput[i]['StationName'])\n",
    "            tmp_event_scatter.append(tmp_event)      \n",
    "        # 返回站点能见度数据\n",
    "        VV_min_scatter = []\n",
    "        for i in VV_scatter_list:\n",
    "            dic_VV_min = {\"value\":[],\"url\":\"\"}\n",
    "            dic_VV_min['value'].append(self.station_dot_comput[str(i)]['lon'])\n",
    "            dic_VV_min['value'].append(self.station_dot_comput[str(i)]['lat'])\n",
    "            dic_VV_min['value'].append(self.station_dot_comput[str(i)]['VV'])\n",
    "            dic_VV_min['url'] =\"station/\"+str(self.station_dot_comput[str(i)]['IIiii'])\n",
    "            dic_VV_min['name'] = str(self.station_dot_comput[str(i)]['StationName'])\n",
    "            VV_min_scatter.append(dic_VV_min) \n",
    "        # 能见度分级\n",
    "        VV_station_rank = [\n",
    "            { \"value\": station_VV_small, \"name\": '强浓雾' },\n",
    "            { \"value\": station_VV_mid, \"name\": '浓雾' },\n",
    "            { \"value\": station_VV_big, \"name\": '大雾' },\n",
    "            { \"value\": station_VV_huge, \"name\": '雾' },\n",
    "            { \"value\": station_VV_more, \"name\": '轻雾' }\n",
    "        ]\n",
    "        # 大风分级\n",
    "        fFy_station_rank = [\n",
    "            { \"value\": station_wind7, \"name\": '7级' },\n",
    "            { \"value\": station_wind8, \"name\": '8级' },\n",
    "            { \"value\": station_wind9, \"name\": '9级' },\n",
    "            { \"value\": station_wind10, \"name\": '10级' },\n",
    "            { \"value\": station_wind11, \"name\": '11级' },\n",
    "            { \"value\": station_wind12, \"name\": '12级' },\n",
    "            { \"value\": station_wind13, \"name\": '13级' },\n",
    "            { \"value\": station_wind14, \"name\": '14级' },\n",
    "            { \"value\": station_wind15, \"name\": '15级' },\n",
    "            { \"value\": station_wind16, \"name\": '16级' },\n",
    "            { \"value\": station_wind17, \"name\": '17级' },        \n",
    "        ]\n",
    "        # 返回站点级大风数据\n",
    "        fFy_wind7up_scatter = []\n",
    "        fFy_name = []\n",
    "        fFy_county= []\n",
    "        fFy_town = []\n",
    "        fFy_value = []\n",
    "        symbol_ffy = ['path://M10 10L50 10 50 20 20 20 20 40 50 40 50 50 20 50 20 100 10 100 10 10z']\n",
    "        for i in fFy_scater_list:\n",
    "            dic_fFy = {\"value\":[],\"url\":\"\"}\n",
    "            fFy_name.append(self.station_dot_comput[str(i)]['IIiii'])\n",
    "            fFy_county.append(self.station_dot_comput[str(i)]['county'])\n",
    "            fFy_town.append(self.station_dot_comput[str(i)]['Town'])\n",
    "            fFy_value.append(self.station_dot_comput[str(i)]['fFy'])\n",
    "            dic_fFy['value'].append(self.station_dot_comput[str(i)]['lon'])\n",
    "            dic_fFy['value'].append(self.station_dot_comput[str(i)]['lat'])\n",
    "            dic_fFy['value'].append(self.station_dot_comput[str(i)]['fFy'])\n",
    "\n",
    "            dic_fFy['symbol'] = str(symbol_ffy[0])\n",
    "            dic_fFy['symbolRotate'] = self.station_dot_comput[str(i)]['dFy']\n",
    "            dic_fFy['url'] =\"station/\"+str(self.station_dot_comput[str(i)]['IIiii'])\n",
    "            dic_fFy['name'] = str(self.station_dot_comput[str(i)]['StationName'])\n",
    "            fFy_wind7up_scatter.append(dic_fFy) \n",
    "        # 按照级大风进行排序\n",
    "        data_fFy =  pd.DataFrame()\n",
    "        data_fFy['name'] = fFy_name \n",
    "        data_fFy['county'] = fFy_county\n",
    "        data_fFy['town'] = fFy_town\n",
    "        data_fFy['fFy'] = fFy_value\n",
    "        data_fFy['index']=data_fFy['fFy'].rank(ascending=0,method='dense')\n",
    "        data_fFy_all = data_fFy.sort_values(by =['fFy'],ascending = [False])  \n",
    "        data_fFy_list = []\n",
    "        for row in data_fFy_all.itertuples():\n",
    "            dic_ffy = {'index':int(getattr(row, 'index')),'IIiii':str(getattr(row, 'name')),\n",
    "            'county':getattr(row, 'county'),'town':getattr(row, 'town'),'data':getattr(row, 'fFy')}\n",
    "            data_fFy_list.append(dic_ffy)\n",
    "\n",
    "        max_fFy_station = data_fFy_all['name'].iloc[0] \n",
    "        data_fFymax =  pd.DataFrame()\n",
    "        data_fFymax['tTime']= self.station_dot_comput[max_fFy_station]['tTime']\n",
    "        data_fFymax['fFy']= self.station_dot_comput[max_fFy_station]['fFyList'] \n",
    "        data_fFymax['dFy']= self.station_dot_comput[max_fFy_station]['dFyList']  \n",
    "        # print(data_fFy_all,max_fFy_station)\n",
    "        return data_rr_plot,level_rain,RR_rx ,RR_sum,RR_station_rank,RR_station_bar,tmp_station_bar,tmp_min_scatter,tmp_max_scatter,tmp_event_scatter,data_vvmin.sort_values(by = 'tTime'),VV_min_scatter,VV_station_rank,data_fFy_list,fFy_wind7up_scatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:6786: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n",
      "[  0.     15.925  31.85   47.775  63.7    79.625  95.55  111.475 127.4  ]\n",
      "CPU times: user 43.5 s, sys: 3.47 s, total: 46.9 s\n",
      "Wall time: 47.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sql = \"test\"\n",
    "RR_County,tmp_max_County,tmp_min_County =  sql_data(sql).comput_county() \n",
    "data_rr_plot,level_rain,RR_rx ,RR_sum,RR_station_rank ,RR_station_bar,tmp_station_bar,tmp_min_scatter,tmp_max_scatter,tmp_event_scatter,data_vvmin,VV_min_scatter,VV_station_rank,data_fFy_list,fFy_wind7up_scatter = sql_data(sql).comput_IIiii()\n",
    "    # 绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 并发运行脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gevent/_config.py:41: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  new_class = type.__new__(cls, name, bases, cls_dict)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------1------\n",
      "------2------\n",
      "------3------\n",
      "------4------\n",
      "<Greenlet at 0x7fcce15b6b90: f1(5)> 0\n",
      "<Greenlet at 0x7fcce15b6cb0: f2(5)> 0\n",
      "<Greenlet at 0x7fcce15b6dd0: f3(5)> 0\n",
      "<Greenlet at 0x7fcce15b6b90: f1(5)> 1\n",
      "<Greenlet at 0x7fcce15b6cb0: f2(5)> 1\n",
      "<Greenlet at 0x7fcce15b6dd0: f3(5)> 1\n",
      "<Greenlet at 0x7fcce15b6b90: f1(5)> 2\n",
      "<Greenlet at 0x7fcce15b6cb0: f2(5)> 2\n",
      "<Greenlet at 0x7fcce15b6dd0: f3(5)> 2\n",
      "<Greenlet at 0x7fcce15b6b90: f1(5)> 3\n",
      "<Greenlet at 0x7fcce15b6cb0: f2(5)> 3\n",
      "<Greenlet at 0x7fcce15b6dd0: f3(5)> 3\n",
      "<Greenlet at 0x7fcce15b6b90: f1(5)> 4\n",
      "<Greenlet at 0x7fcce15b6cb0: f2(5)> 4\n",
      "<Greenlet at 0x7fcce15b6dd0: f3(5)> 4\n"
     ]
    }
   ],
   "source": [
    "import gevent\n",
    "import time\n",
    "# 如果需要默认的 time.sleep(0.5) 需要打补丁\n",
    "from gevent import monkey\n",
    "monkey.patch_all()\n",
    "\n",
    "\n",
    "def f1(n):\n",
    "    for i in range(n):\n",
    "        print(gevent.getcurrent(), i)\n",
    "        # gevent.sleep(0.5)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "def f2(n):\n",
    "    for i in range(n):\n",
    "        print(gevent.getcurrent(), i)\n",
    "        # gevent.sleep(0.5)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "def f3(n):\n",
    "    for i in range(n):\n",
    "        print(gevent.getcurrent(), i)\n",
    "        # gevent.sleep(0.5)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "\n",
    "print(\"------1------\")\n",
    "g1 = gevent.spawn(f1, 5)\n",
    "print(\"------2------\")\n",
    "g2 = gevent.spawn(f2, 5)\n",
    "print(\"------3------\")\n",
    "g3 = gevent.spawn(f3, 5)\n",
    "print(\"------4------\")\n",
    "g1.join()\n",
    "g2.join()\n",
    "g3.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "CPU times: user 13.3 ms, sys: 0 ns, total: 13.3 ms\n",
      "Wall time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "items = [x for x in range(1, 100)]\n",
    "\n",
    "pool = ThreadPool(4)\n",
    "\n",
    "def process(data):\n",
    "    stra = '666' \n",
    "#     print(data)\n",
    "    \n",
    "\n",
    "pool.map(process, items)\n",
    "\n",
    "pool.close()\n",
    "\n",
    "pool.join()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "CPU times: user 1.87 ms, sys: 202 µs, total: 2.07 ms\n",
      "Wall time: 1.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "items = [x for x in range(1, 10000)]\n",
    "for i in items:\n",
    "    strs = 'sdf'\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single processing time: 55.84110653500102 s\n",
      "[4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import timeit\n",
    "import operator\n",
    "def do_something(x):\n",
    "    v = pow(x, 2)\n",
    "    return v\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a =[]\n",
    "    start = timeit.default_timer()\n",
    "    for i in range(1, 100000000):\n",
    "        a.append(do_something(i))\n",
    "\n",
    "    end = timeit.default_timer()\n",
    "    print('single processing time:', str(end-start), 's')\n",
    "    print(a[1:10])\n",
    "\n",
    "\t# revise to parallel\n",
    "    items = [x for x in range(1, 100000000)]\n",
    "    p = multiprocessing.Pool(4)\n",
    "    start = timeit.default_timer()\n",
    "    b = p.map(do_something, items)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    end = timeit.default_timer()\n",
    "    print('multi processing time:', str(end-start),'s')\n",
    "    print(b[1:10])\n",
    "    print('Return values are all equal ?:', operator.eq(a, b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 协程的终极方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 17.6 ms, total: 163 ms\n",
      "Wall time: 6.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gevent\n",
    "import requests\n",
    "import time\n",
    "g_lista = []\n",
    "for i in range(10):\n",
    "    res = requests.get('http://www.baidu.com')\n",
    "    g_lista.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 535 ms, sys: 49.6 ms, total: 585 ms\n",
      "Wall time: 582 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gevent\n",
    "import requests\n",
    "import time\n",
    "     \n",
    "def get_res(url):\n",
    "    res = requests.get(url)\n",
    "    print(res.content.decode('utf-8'))\n",
    "     \n",
    "\n",
    "g_lista = []\n",
    "start_time=time.time()\n",
    "for i in range(55000):\n",
    "    g = gevent.spawn(get_res, 'http://www.baidu.com')\n",
    "    #print(g.join())\n",
    "    g_lista.append(g)\n",
    "    #print(i, flush=True)\n",
    "#print(len(g_lista))\n",
    "# [a.join() for a in g_lista]\n",
    "# end_time = time.time() - start_time\n",
    "#print(end_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
